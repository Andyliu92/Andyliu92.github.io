<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>格致集 on 知止堂</title><link>https://blog.comfluter.life/categories/%E6%A0%BC%E8%87%B4%E9%9B%86/</link><description>Recent content in 格致集 on 知止堂</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 08 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.comfluter.life/categories/%E6%A0%BC%E8%87%B4%E9%9B%86/index.xml" rel="self" type="application/rss+xml"/><item><title>ConvLab-2 Toolkit</title><link>https://blog.comfluter.life/p/convlab-2-toolkit/</link><pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/convlab-2-toolkit/</guid><description>Download toolkit git clone https://github.com/mozilla/TTS.git
Install and config env conda create -n convlab2 python=3.6.2 cd ConvLab-2 install cpu version of pytorch (run on personal computer)conda install pytorch==1.5.1 torchvision==0.6.1 cpuonly -c pytorch otherwise, auto installation cannot find package version. pip install -e .</description></item><item><title>Early-Exit BERT 组会记录</title><link>https://blog.comfluter.life/p/early-exit-bert-%E7%BB%84%E4%BC%9A%E8%AE%B0%E5%BD%95/</link><pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/early-exit-bert-%E7%BB%84%E4%BC%9A%E8%AE%B0%E5%BD%95/</guid><description>2022.02.07 组会 简单讨论了一下我对于Early-Exit BERT的理解，解答了一些问题，确定了下一步代码层面的工作内容。
2月7日和刘时宜讨论：early-exit
周晨晨意见：把FSA的各个模型，让刘时宜学弟先尝试用early-exit加速某一个，然后推广到其他模型；在服务器上，新建一个目录开始尝试。
周晨晨问题：Huggingface-Transformer版本问题；
谢克力意见：先简单复现FastBERT的开源代码，再类比，把early-eixt的方法推广；
刘时宜的工作顺序：
简单复现FastBERT的开源代码，深入了解一下early-exit的具体操作，可能还包含了蒸馏的操作 复现完成之后，我们再看如何推广到我们现有的FSA模型上。 周晨晨的工作顺序：
先尝试一下能否在distillBERT上做early-exit。</description></item><item><title>FastBERT</title><link>https://blog.comfluter.life/p/fastbert/</link><pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/fastbert/</guid><description>Install on Surface Pro 7 Download and config FastBERT FastBERT git rep
git clone https://github.com/autoliuweijie/FastBERT.git conda create -n fastbert python=3.8.2 conda activate fastbert cd .\FastBERT\ conda install pytorch==1.5.1 torchvision==0.6.1 cpuonly -c pytorch pip install -r requirements.txt Quick start on the Chinese Book review dataset Download the pre-trained Chinese BERT parameters from here, and save it to the models directory with the name of &amp;ldquo;Chinese_base_model.bin&amp;rdquo;. Install on server with CUDA git clone https://github.</description></item><item><title>Debugging ToD-BERT with vscode</title><link>https://blog.comfluter.life/p/debugging-tod-bert-with-vscode/</link><pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/debugging-tod-bert-with-vscode/</guid><description>Configuring launch.json in vscode &amp;#34;configurations&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;Python: my tod training&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;python&amp;#34;, &amp;#34;request&amp;#34;: &amp;#34;launch&amp;#34;, &amp;#34;program&amp;#34;: &amp;#34;${file}&amp;#34;, &amp;#34;console&amp;#34;: &amp;#34;integratedTerminal&amp;#34;, &amp;#34;args&amp;#34;: [ &amp;#34;--task=usdl&amp;#34;, &amp;#34;--model_type=bert&amp;#34;, &amp;#34;--model_name_or_path=bert-base-uncased&amp;#34;, &amp;#34;--output_dir=&amp;#34;, &amp;#34;--do_train&amp;#34;, &amp;#34;--do_eval&amp;#34;, &amp;#34;--mlm&amp;#34;, &amp;#34;--do_lower_case&amp;#34;, &amp;#34;--evaluate_during_training&amp;#34;, &amp;#34;--save_steps=2500&amp;#34;, &amp;#34;--logging_steps=1000&amp;#34;, &amp;#34;--per_gpu_train_batch_size=1&amp;#34;, &amp;#34;--per_gpu_eval_batch_size=1&amp;#34;, &amp;#34;--only_last_turn&amp;#34; ] } ] Running Debug Session open my_tod_pretraining.py and press F5 to start a debug session using the configuration shown above.
bug report:
initial bug report
initial bug console report</description></item><item><title>大创对话系统21.12.06组会</title><link>https://blog.comfluter.life/p/%E5%A4%A7%E5%88%9B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F21.12.06%E7%BB%84%E4%BC%9A/</link><pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/%E5%A4%A7%E5%88%9B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F21.12.06%E7%BB%84%E4%BC%9A/</guid><description>任务 断点调试：解决training时参数错误的TypeError 使用vscode中launch.json加入args参数 问题 ToD-BERT模型适用性？ 数据搬运是否是性能瓶颈？</description></item><item><title>服务器配置CPU版ToD-BERT环境</title><link>https://blog.comfluter.life/p/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEcpu%E7%89%88tod-bert%E7%8E%AF%E5%A2%83/</link><pubDate>Wed, 24 Nov 2021 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEcpu%E7%89%88tod-bert%E7%8E%AF%E5%A2%83/</guid><description>Conda 复制已有环境 由于服务器上本身已经有使用CUDA平台的ToD-BERT运行环境，仅需将此环境中所有使用GPU的库换为使用CPU的库即可：pytorch
查看已有环境
(base) dialogue@amax-13:/$ conda info --env # conda environments: # base * /media/HD1/dche/miniconda3 sum_env /media/HD1/dche/miniconda3/envs/sum_env tod_bert /media/HD1/dche/miniconda3/envs/tod_bert /media/HD1/miniconda3 创建新环境，并将原有环境中的所有包复制，并激活新建立的环境。
(base) dialogue@amax-13:/$ conda create -n tod_bert_cpu --clone tod_bert Source: /media/HD1/dche/miniconda3/envs/tod_bert Destination: /media/HD1/dche/miniconda3/envs/tod_bert_cpu Packages: 20 Files: 12683 Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate tod_bert_cpu # # To deactivate an active environment, use # # $ conda deactivate (base) dialogue@amax-13:/$ conda activate tod_bert_cpu (tod_bert_cpu) dialogue@amax-13:/$ Conda配置环境中的包（卸载GPU版本、安装CPU版本） Conda 查看环境中所有包的信息</description></item><item><title>大创对话系统21.11.22组会</title><link>https://blog.comfluter.life/p/%E5%A4%A7%E5%88%9B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F21.11.22%E7%BB%84%E4%BC%9A/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/%E5%A4%A7%E5%88%9B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F21.11.22%E7%BB%84%E4%BC%9A/</guid><description>问题 设备选择： 主要参数：内存 GPU 设备：jetson更好 树莓派算力有限，人工智能框架支持不官方 jetson有关方支持 tensor+树莓派能媲美jetson+tensor IO口 Tod-BERT fine tune 精调后的inference time &amp;amp; 内存占用？ ToD-inference time 单位？ 任务 树莓派装pytorch ToD-BERT 在树莓派上训练、推理 ToD-BERT fine tune ToD-BERT inference time 想测在一个卡上batch size = 1时候的推理时间 cuda.event时间数值的单位？ time包中测出来的时间？ 10ms级别 使用time包测量的方法
服务器CPU运行测量 training 限制CPU核心数量4 batch size = 1，2，4 重新配置conda环境，安装CPU版本pytorch 配置conda环境教程 用time模块测量 立项答辩 突出动机 抓住评委兴趣 语速、文字减少，减少技术细节 突出重音、重点 每人提2条意见 应用场景 边缘端部署 内存需求 算力需求</description></item><item><title>希尔伯特曲线项目每周进展</title><link>https://blog.comfluter.life/p/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E6%9B%B2%E7%BA%BF%E9%A1%B9%E7%9B%AE%E6%AF%8F%E5%91%A8%E8%BF%9B%E5%B1%95/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E6%9B%B2%E7%BA%BF%E9%A1%B9%E7%9B%AE%E6%AF%8F%E5%91%A8%E8%BF%9B%E5%B1%95/</guid><description>21.12.17 与王凯师兄讨论 已完成 根据具体电路电阻参数，完成最大电流信号、最小电流step的估计 下一步 SPAD导通电阻误差10%的情况下，数值解出对于电流值的影响 画出电流大小分布图、累积概率图 调整SPAD参数，使得最小电流精度与最大电流值之比为8bit（最差12bit） 21.12.10 与王凯师兄讨论 已完成 3阶、4阶信号最小step、最大值数量级估计 下一步 拿到SPAD导通以及截至电阻，算出具体最小step、最大值 最小step用作器件精度要求，最大值用于器件量程要求 21.12.03 与王凯师兄讨论 已完成 两光子信号的分辨方法。 下一步任务 电流精度问题，考虑器件电阻（三极管导通电阻）的问题。 结合半导体CMOS工艺M1层方块电阻进行计算。 21.11.25 与王凯师兄讨论 已完成 电流信号最小step 电流信号大小极差 考虑信号传输时间的条件下，2光子的应对策略 下一步任务 不用考虑信号传输时间，两光子同时到达的情况如何分辨？ 参考以往论文 如何使用更少的信息分辨？ 21.11.11 与王凯师兄讨论 已经完成的进展 希尔伯特曲线位置到平面位置映射 单光子信号函数关系（电流、时间差） 下一步任务 推导单光子电流信号范围、min step 两光子信号的分辨（电流+时间差） 能否只用电流不用时间差？（对于极端状况不行？） 时间差能否被分辨？ 不同位置信号乱序到达，如何处理 统一单光子与多光子探测方法</description></item><item><title>视网膜初级处理项目进展</title><link>https://blog.comfluter.life/p/%E8%A7%86%E7%BD%91%E8%86%9C%E5%88%9D%E7%BA%A7%E5%A4%84%E7%90%86%E9%A1%B9%E7%9B%AE%E8%BF%9B%E5%B1%95/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/%E8%A7%86%E7%BD%91%E8%86%9C%E5%88%9D%E7%BA%A7%E5%A4%84%E7%90%86%E9%A1%B9%E7%9B%AE%E8%BF%9B%E5%B1%95/</guid><description>21.12.10 与王凯师兄讨论 已完成 Photoreceptor 论文阅读 依据“抑制能力”进行调参 空间频率信号仿真 Pyspice任意源使用方法 下一步 学习使用pyspice lib文件导入以及使用方法 仿真Photoreceptor电路 21.12.03 与王凯师兄讨论 已完成 仿真图像激励突然消失时的瞬态响应 仿真结果视频输出 下一步 依据视网膜边缘抑制能力调整电路参数 不同空间频率信号仿真 阅读文献，仿真更复杂的模型。 Photoreceptor 取对数电路 关于项目目的 人的视觉信号，在视锥细胞、视杆细胞层面信息量有1Tbps，但是传入人脑的信息只有10Mbps。这充分说明在观察一幅图像时，不需要那么多的信息，不需要记录每一个像素点的灰度信息。例如自然界中成像结果中大部分信息是缓变的，不需要每个像素点都按照绝对大小所需的数据精度进行记录。因此希望探究视网膜对于信号的处理方法，理论上建模出其提取的图像信息，再进行优化，指导新型成像器件、新型图片格式的形成。
而且，上述涉及到的操作可以不通过额外、单独的处理电路进行处理，而是在器件层面直接进行处理。远景目标考虑使用SNN（Spike Neuron Network，脉冲神经网络）完成整个图像的输入输出。
21.11.25 与王凯师兄讨论 已完成 Pyspice仿真静态图像阶跃输入时的瞬态响应 下一步 仿真激励突然消失时，电路的响应 仿真有初始条件状态下的零输入响应即可 视频输入的响应 21.11.11 与王凯师兄讨论 已经完成的工作： 使用pyspice，仿真出电阻网络对于特定信号的响应 下一步计划： 利用四边形连接方式，仿真出： 对于静态图片的响应 对于动态图片的响应，做成视频 改为六边形连接方式进行仿真。 需要六边形超分辨率的知识，数学上暂时存在困难，需等待师兄仿真完成。</description></item><item><title>ToD-BERT 相关内容</title><link>https://blog.comfluter.life/p/tod-bert-%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/</link><pubDate>Sun, 21 Nov 2021 00:00:00 +0000</pubDate><guid>https://blog.comfluter.life/p/tod-bert-%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/</guid><description>ToD-BERT the Paper 数据集 不同的数据集可以帮助模型达到不同的熟练效果
MetaLWOZ 预测数据 &amp;hellip; ToD-BERT怎么训练的？ mlm contrastive function 两者都有误差，因此才可以被训练。 空间结构能够捕获差异，发现细微结构。 在服务器上运行ToD-BERT训练 进入服务器，激活环境source activate todbert_env 进入/media/HD1/dche/ToD-BERT文件夹cd /media/HD1/dche/ToD-BERT 查看GPU资源占用情况nvidia-smi，然后选择目前占用情况较低的一张GPU进行训练即可 运行训练shell脚本文件CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets。根据第三步选择的几号卡，就把对应的0改成几，此处默认单卡训练。如果一切正常的话，再读入数据集数据后，就会开始训练了，有进度条出现就Ok了。常见的没跑起来的情况是CUDA out of memory。 ToD-BERT本地调用 将ToD-BERT模型下载至本地 包含ToD-BERT所需的python包，并定义模型路径 import torch from transformers import * BERT = &amp;lt;path_to_the_downloaded_tod-bert&amp;gt; # 注意此处的路径要使用从根目录开始的绝对路径，而非从用户~目录开始的相对路径。 model_class, tokenizer_class, config_class = BertModel, BertTokenizer, BertConfig tokenizer = tokenizer_class.from_pretrained(BERT) tod_bert = model_class.from_pretrained(BERT) 使用ToD-BERT文档中的示例 # Encode text input_text = &amp;#34;[CLS] [SYS] Hello, what can I help with you today?</description></item></channel></rss>