<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>格致之道 on 知止堂</title><link>https://comfluter.life/categories/%E6%A0%BC%E8%87%B4%E4%B9%8B%E9%81%93/</link><description>Recent content in 格致之道 on 知止堂</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 24 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://comfluter.life/categories/%E6%A0%BC%E8%87%B4%E4%B9%8B%E9%81%93/index.xml" rel="self" type="application/rss+xml"/><item><title>服务器配置CPU版ToD-BERT环境</title><link>https://comfluter.life/p/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEcpu%E7%89%88tod-bert%E7%8E%AF%E5%A2%83/</link><pubDate>Wed, 24 Nov 2021 00:00:00 +0000</pubDate><guid>https://comfluter.life/p/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEcpu%E7%89%88tod-bert%E7%8E%AF%E5%A2%83/</guid><description>Conda 复制已有环境 由于服务器上本身已经有使用CUDA平台的ToD-BERT运行环境，仅需将此环境中所有使用GPU的库换为使用CPU的库即可：pytorch
查看已有环境
(base) dialogue@amax-13:/$ conda info --env # conda environments: # base * /media/HD1/dche/miniconda3 sum_env /media/HD1/dche/miniconda3/envs/sum_env tod_bert /media/HD1/dche/miniconda3/envs/tod_bert /media/HD1/miniconda3 创建新环境，并将原有环境中的所有包复制，并激活新建立的环境。
(base) dialogue@amax-13:/$ conda create -n tod_bert_cpu --clone tod_bert Source: /media/HD1/dche/miniconda3/envs/tod_bert Destination: /media/HD1/dche/miniconda3/envs/tod_bert_cpu Packages: 20 Files: 12683 Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate tod_bert_cpu # # To deactivate an active environment, use # # $ conda deactivate (base) dialogue@amax-13:/$ conda activate tod_bert_cpu (tod_bert_cpu) dialogue@amax-13:/$ Conda配置环境中的包（卸载GPU版本、安装CPU版本） Conda 查看环境中所有包的信息</description></item><item><title>大创对话系统21.11.22组会</title><link>https://comfluter.life/p/%E5%A4%A7%E5%88%9B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F21.11.22%E7%BB%84%E4%BC%9A/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://comfluter.life/p/%E5%A4%A7%E5%88%9B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F21.11.22%E7%BB%84%E4%BC%9A/</guid><description>问题 设备选择： 主要参数：内存 GPU 设备：jetson更好 树莓派算力有限，人工智能框架支持不官方 jetson有关方支持 tensor+树莓派能媲美jetson+tensor IO口 Tod-BERT fine tune 精调后的inference time &amp;amp; 内存占用？ ToD-inference time 单位？ 任务 树莓派装pytorch ToD-BERT 在树莓派上训练、推理 ToD-BERT fine tune ToD-BERT inference time 想测在一个卡上batch size = 1时候的推理时间 cuda.event时间数值的单位？ time包中测出来的时间？ 10ms级别 使用time包测量的方法 服务器CPU运行测量 training 限制CPU核心数量4 batch size = 1，2，4 重新配置conda环境，安装CPU版本pytorch 配置conda环境教程 用time模块测量 立项答辩 突出动机 抓住评委兴趣 语速、文字减少，减少技术细节 突出重音、重点 每人提2条意见 应用场景 边缘端部署 内存需求 算力需求</description></item><item><title>希尔伯特曲线项目每周进展</title><link>https://comfluter.life/p/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E6%9B%B2%E7%BA%BF%E9%A1%B9%E7%9B%AE%E6%AF%8F%E5%91%A8%E8%BF%9B%E5%B1%95/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://comfluter.life/p/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E6%9B%B2%E7%BA%BF%E9%A1%B9%E7%9B%AE%E6%AF%8F%E5%91%A8%E8%BF%9B%E5%B1%95/</guid><description>21.11.25 与王凯师兄讨论 已完成 电流信号最小step 电流信号大小极差 考虑信号传输时间的条件下，2光子的应对策略 下一步任务 不用考虑信号传输时间，两光子同时到达的情况如何分辨？ 参考以往论文 如何使用更少的信息分辨？ 21.11.11 与王凯师兄讨论 已经完成的进展 希尔伯特曲线位置到平面位置映射 单光子信号函数关系（电流、时间差） 下一步任务 推导单光子电流信号范围、min step 两光子信号的分辨（电流+时间差） 能否只用电流不用时间差？（对于极端状况不行？） 时间差能否被分辨？ 不同位置信号乱序到达，如何处理 统一单光子与多光子探测方法</description></item><item><title>视网膜初级处理项目进展</title><link>https://comfluter.life/p/%E8%A7%86%E7%BD%91%E8%86%9C%E5%88%9D%E7%BA%A7%E5%A4%84%E7%90%86%E9%A1%B9%E7%9B%AE%E8%BF%9B%E5%B1%95/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://comfluter.life/p/%E8%A7%86%E7%BD%91%E8%86%9C%E5%88%9D%E7%BA%A7%E5%A4%84%E7%90%86%E9%A1%B9%E7%9B%AE%E8%BF%9B%E5%B1%95/</guid><description>21.11.25 与王凯师兄讨论 已完成 Pyspice仿真静态图像阶跃输入时的瞬态响应 下一步 仿真激励突然消失时，电路的响应 仿真有初始条件状态下的零输入响应即可 视频输入的响应 21.11.11 与王凯师兄讨论 已经完成的工作： 使用pyspice，仿真出电阻网络对于特定信号的响应 下一步计划： 利用四边形连接方式，仿真出： 对于静态图片的响应 对于动态图片的响应，做成视频 改为六边形连接方式进行仿真。 需要六边形超分辨率的知识，数学上暂时存在困难，需等待师兄仿真完成。</description></item><item><title>ToD-BERT 相关内容</title><link>https://comfluter.life/p/tod-bert-%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/</link><pubDate>Sun, 21 Nov 2021 00:00:00 +0000</pubDate><guid>https://comfluter.life/p/tod-bert-%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/</guid><description>在服务器上运行ToD-BERT训练 进入服务器，激活环境source activate todbert_env 进入/media/HD1/dche/ToD-BERT文件夹cd /media/HD1/dche/ToD-BERT 查看GPU资源占用情况nvidia-smi，然后选择目前占用情况较低的一张GPU进行训练即可 运行训练shell脚本文件CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets。根据第三步选择的几号卡，就把对应的0改成几，此处默认单卡训练。如果一切正常的话，再读入数据集数据后，就会开始训练了，有进度条出现就Ok了。常见的没跑起来的情况是CUDA out of memory。 ToD-BERT本地调用 将ToD-BERT模型下载至本地 包含ToD-BERT所需的python包，并定义模型路径 import torch from transformers import * BERT = &amp;lt;path_to_the_downloaded_tod-bert&amp;gt; # 注意此处的路径要使用从根目录开始的绝对路径，而非从用户~目录开始的相对路径。 model_class, tokenizer_class, config_class = BertModel, BertTokenizer, BertConfig tokenizer = tokenizer_class.from_pretrained(BERT) tod_bert = model_class.from_pretrained(BERT) 使用ToD-BERT文档中的示例 # Encode text input_text = &amp;#34;[CLS] [SYS] Hello, what can I help with you today? [USR] Find me a cheap restaurant nearby the north town.</description></item></channel></rss>