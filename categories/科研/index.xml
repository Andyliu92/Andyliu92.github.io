<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>科研 on 知止堂</title>
    <link>https://comfluter.life/categories/%E7%A7%91%E7%A0%94/</link>
    <description>Recent content in 科研 on 知止堂</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 22 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://comfluter.life/categories/%E7%A7%91%E7%A0%94/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>希尔伯特曲线项目每周进展</title>
      <link>https://comfluter.life/p/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E6%9B%B2%E7%BA%BF%E9%A1%B9%E7%9B%AE%E6%AF%8F%E5%91%A8%E8%BF%9B%E5%B1%95/</link>
      <pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://comfluter.life/p/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E6%9B%B2%E7%BA%BF%E9%A1%B9%E7%9B%AE%E6%AF%8F%E5%91%A8%E8%BF%9B%E5%B1%95/</guid>
      <description>21.11.11 与王凯师兄讨论 已经完成的进展  希尔伯特曲线位置到平面位置映射 单光子信号函数关系（电流、时间差）  下一步任务  推导单光子电流信号范围、min step 两光子信号的分辨（电流+时间差）  能否只用电流不用时间差？（对于极端状况不行？） 时间差能否被分辨？ 不同位置信号乱序到达，如何处理   统一单光子与多光子探测方法  </description>
    </item>
    
    <item>
      <title>视网膜初级处理项目进展</title>
      <link>https://comfluter.life/p/%E8%A7%86%E7%BD%91%E8%86%9C%E5%88%9D%E7%BA%A7%E5%A4%84%E7%90%86%E9%A1%B9%E7%9B%AE%E8%BF%9B%E5%B1%95/</link>
      <pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://comfluter.life/p/%E8%A7%86%E7%BD%91%E8%86%9C%E5%88%9D%E7%BA%A7%E5%A4%84%E7%90%86%E9%A1%B9%E7%9B%AE%E8%BF%9B%E5%B1%95/</guid>
      <description>21.11.11 与王凯师兄讨论 已经完成的工作：  使用pyspice，仿真出电阻网络对于特定信号的响应  下一步计划：  利用四边形连接方式，仿真出：  对于静态图片的响应 对于动态图片的响应，做成视频   改为六边形连接方式进行仿真。  需要六边形超分辨率的知识，数学上暂时存在困难，需等待师兄仿真完成。    参考资料 [王凯师兄视网膜调研](D:\Work\04 Research Project\21.08.19 Early Visual Processing\references\2021.10.13 视网膜调研.pptx)</description>
    </item>
    
    <item>
      <title>ToD-BERT 相关内容</title>
      <link>https://comfluter.life/p/tod-bert-%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/</link>
      <pubDate>Sun, 21 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://comfluter.life/p/tod-bert-%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/</guid>
      <description>在服务器上运行ToD-BERT训练  进入服务器，激活环境source activate todbert_env 进入/media/HD1/dche/ToD-BERT文件夹cd /media/HD1/dche/ToD-BERT 查看GPU资源占用情况nvidia-smi，然后选择目前占用情况较低的一张GPU进行训练即可 运行训练shell脚本文件CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets。根据第三步选择的几号卡，就把对应的0改成几，此处默认单卡训练。如果一切正常的话，再读入数据集数据后，就会开始训练了，有进度条出现就Ok了。常见的没跑起来的情况是CUDA out of memory。  ToD-BERT本地调用  将ToD-BERT模型下载至本地 包含ToD-BERT所需的python包，并定义模型路径 import torch from transformers import * BERT = &amp;lt;path_to_the_downloaded_tod-bert&amp;gt; # 注意此处的路径要使用从根目录开始的绝对路径，而非从用户~目录开始的相对路径。 model_class, tokenizer_class, config_class = BertModel, BertTokenizer, BertConfig tokenizer = tokenizer_class.from_pretrained(BERT) tod_bert = model_class.from_pretrained(BERT)  使用ToD-BERT文档中的示例 # Encode text  input_text = &amp;#34;[CLS] [SYS] Hello, what can I help with you today? [USR] Find me a cheap restaurant nearby the north town.</description>
    </item>
    
  </channel>
</rss>
