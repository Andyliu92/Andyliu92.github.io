[{"content":"序言 在经历许许多多的学习、配置、折腾之后，终于在今天配置好了自己的个人博客。\n在朋友圈、微博盛行的当下，个人博客的风头已过，好像已经是上一个时代的产物了。那么究竟又是什么让我在建站的过程中即使遇到了层层困难，也坚定不移地搭起来这个博客呢？\n第一方面，感觉自己还是需要一个记录与对外表达的窗口。朋友圈等等社交网络固然可以，但是于我来讲似乎显得喧闹了些。我期待的表达，不是浮于表面的事件记录与短暂的情感宣泄。静下心来记录自己成长变化、各阶段真实想法与所思所得才是我我之所需。而这些想法，有时又期待能随时随地回顾，或是与志同道合之人分享。因此介于朋友圈、微博等社交平台与传统纸笔日记之间的个人博客似乎是个不错的选择。从半年前看到王凯师兄的博客便觉心动，到现在终于有了属于自己的一方空间。\n此外，也是最近在学习计算机网络的相关课程。从之前分不清HTTP、URL、TCP等等名词之间的关系的状态一步步地了解了网络的各个方面，而因为课程设计原因深感实践不足。云服务器的配置、连接、博客的搭建与部署、域名的申请与域名解析配置等等正好为动手实践课程内容提供了一个极佳的机会。在搭建服务器、部署博客的过程中也确实不断地将课本中抽象的知识落到实处。\n最后，可能也是最近受龄的影响，觉得自己不能再一天天想着GPA就惶惶不可终日。成天担心对成绩的影响而束手束脚，投入了过多不必要的时间在课业的细枝末节上，生怕漏掉一小点就会有多么大的影响。现在我觉得比较好的态度是：应该投入的时间，我保证投入。除此之外，偶然性是必然有的，考试中等等可能出现的意外情况、偏门的微末之处，实在无必要，也无意义为了它们投入大量的时间。投入了，也不能保证最后的结果。与其如此，正如闫锋老师说的，不如让自己真正做点实在的事出来，在实践中学习，在实践中收获，在主动地做事情的过程当中发挥自己心灵的能动性，让自己过得由己、恣肆、多彩一些。\n因此，也希望这个博客在记录我个人所思所想以外，能够带动我走出一天天为了成绩而焦虑的状态之中，真正地敢于放手去做自己喜欢的事，也才真正能做成自己喜欢的事。\n建站小记  21.11.05 购买腾讯云服务器、购买域名comfluter.life，熟悉linux服务器操作与hugo工具基本使用 21.11.13 在询问完王凯师兄hugo博客部署方法以后，学习hugo模板使用与博客搭建、github使用、github actions + 云服务器自动部署。但是卡在了最后一步Nginx服务器配置，使得服务器端页面一直显示404。 21.11.15 由于Nginx服务器的问题，以及之前摸索阶段各种误操作，决定直接重置腾讯云服务器，将服务器端的功能重新搭建。完成服务器基本设置后激活root账户并配置ssh登录信息，重写了github pages，安装Nginx，以root账户运行，配置Nginx。 21.11.19 由于使用主题时采用了git submodule的方式，而github同步时不同步submodule导致各种错误，重新使用git clone方式引入了主题，重新搭建了博客与github repo，并配置github actions。 21.11.19 解决github actions css无法加载问题，使用git submodule直接推送到github pages，但发现问题仍然存在。最终确定问题在baseURL上，改好后部署。 21.11.19 写下这篇hello world文档。  动手去做一个项目确实是学习的高效方法。通过搭建博客，至少熟悉了以下内容：\n 云服务器 Linux命令行 git命令行操作 git submodule github全流程 github pages github actions hugo使用 域名配置与域名解析 防火墙配置 Nginx服务器搭建  其中许多是以前多次觉得应该去做，而没多久又半途而废的。放弃的理由大概是陷入极多的知识内容而毫无方向，也就失去了学习的意义，但为了一个目标去做，许多事情就顺理成章了。\n希望以后能以更多项目为依托，让自己不断学习、进步。\nlink built with hugo and using theme \u0026ldquo;Stack\u0026rdquo;\nStack Chinese documentation\nicons\n","date":"9999-11-19T00:00:00Z","image":"https://comfluter.life/p/hello-world/cover_hu8fe24aed48b4970acc8d4892530f8a6f_213999_120x120_fill_q75_box_smart1.jpg","permalink":"https://comfluter.life/p/hello-world/","title":"Hello, World!"},{"content":"Minutiae 使用taskset命令限定Linux下CPU逻辑核的使用对象及个数 linux下如何查看多核负载情况 LINUX下查看CPU使用率的命令\n","date":"2021-11-25T00:00:00Z","permalink":"https://comfluter.life/p/linux-%E5%AD%A6%E4%B9%A0%E9%9A%8F%E8%AE%B0/","title":"Linux 学习随记"},{"content":"在王凯师兄的推荐下，使用gitalk搭建博客评论功能。\nGithub上申请OAuth application  登录github 在Settings页面选择Developer settings选项。 在Developer settings选择OAuth Apps,然后会在页面右边有一个New OAuth App按钮，点击这个按钮就进入到新建OAuth application页面 填写新建OAuth application相关信息：  Application name：新建应用的名称 Homepage URL：The full URL to your application homepage. eg.https://comfluter.life/ Application description：对新建应用的描述 Authorization callback URL：回调链接，与Homepage URL保持一致即可。 注：这些参数可以在以后修改   点击注册应用，就可以看到Client ID，可以新建一个Client Secret  Hugo 配置 使用stack主题，在配置文件config.yaml中已经预留了相关字段。\n 复制填写刚生成的Client ID，Client Secret。 repo: 类型：字符串，必填，github上的仓库名字，用于存放Gitalk评论 owner: 类型：字符串，必填，github仓库的所有者的名字 admin: 类型：数组(元素是字符串)，必填，github仓库的所有者和合作者 (对这个 repository 有写权限的用户)。如果仓库有多个人可以操作，那么在这里以数组形式写出：['someone']  Debugging Error: Not Found. References Gitalk评论插件使用教程\n","date":"2021-11-25T00:00:00Z","permalink":"https://comfluter.life/p/%E5%8D%9A%E5%AE%A2%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD%E6%90%AD%E5%BB%BA/","title":"博客评论功能搭建"},{"content":"linting using vscode extension Verilog-HDL/SystemVerilog/Bluespec SystemVerilog.\nusing iverilog\ngo to extension settings and set verilog \u0026gt; linting : linter = iverilog\nthen the linting function should work for verilog files.\nNotice:\n the dir to verilog file should not contain chinese characters and spaces. if you imported module from other file without include command, iverilog willl report an error. As it is always the case when using vivado, add -i to extention setting Verilog › Linting › Iverilog: Arguments to ignore this error.  References 用VSCode编辑verilog代码、iverilog编译、自动例化、自动补全、自动格式化等常用插件\n","date":"2021-11-24T00:00:00Z","permalink":"https://comfluter.life/p/verilog-with-vscode/","title":"Verilog with vscode"},{"content":"Multi-module Project Just write two verilog files and instantiate a module specified in the other file, the vivado will figure out the dependencies automatically.\n","date":"2021-11-24T00:00:00Z","permalink":"https://comfluter.life/p/vivado-%E5%AD%A6%E4%B9%A0%E9%9A%8F%E8%AE%B0/","title":"Vivado 学习随记"},{"content":"老子 概述  先秦道家第一部 《老子》文献的真实性：  上世纪20年代，用西方方法考察中国传统文献：有气人，但书可能是后人写的 马王堆汉墓老子帛书抄本 汉文帝时期 证明此时《老子》其书已经盛行  篇目数量差不多   90年代：郭店楚简 其中有《老子》 测年公元前300年，战国中晚期  其中还有较多儒家早期文献 篇目较少，约为传世本1/3，可能为摘抄   此两本出图后，证明《老子》一定成书早于战国晚期。 证实了《老子》应为所有道家文献的原创。 作者到现在还不确定，阅读时不用深究 首创“自然之道”的概念    道 不仅道家讲“道”，其应该为春秋时代出现的思想概念。\n“道”字商代便有，但不是重要思想概念，仅为“道路”之意。“道”在春秋时成为思想概念内涵。从《论语》中可以得到印证。\n含义变化原因：政治变化。以氏族为本位的政治构架在衰弱。以祭祀为本，为期中心概念（西周时）。后来西周衰落，天命观念受到怀疑，上天包庇某一氏族的理念在弱化。孔子时政治基本不讲“天命”，个人也可以讲“天命”。政治的合理性在哪？当时的思想家在寻找新的理解。这个背景下，“道”的观念得以提出。政治的合法性来源：神授\u0026ndash;\u0026gt;往圣先贤的做法，体现出人本主义。\n 《国语》周语下：吾非瞽史，焉知天道？\n 只有知道历史，才知道天道。（史官当时也管天道）此处天道：星象变化的大致规则，引申为自然变化的规则。\n中国的士大夫文化：\n 对中国文化发展影响最深。 非宗教的：思想主流为人文主义的：道德规则、历史传承、品信修养，而非不可知的神意。 道为非常重要的概念。  道为其他概念的中心：仁义礼智等等\n自然之道：一种特别的道  《老子》二十五章：人法地，地法天，天法道，道法自然 “道可道非常道”\n 自然之道的含义 自然：名词？ \u0026mdash;\u0026gt; 天地万物的规则\n自然是动词！ 意为“自己这样”，万物自己演化的规律。\n人应当效法自然：不是效法自然的规律，而是效法自己如此的状态。\n 第七章：天长地久。天地所以能长且久者，以其不自生，故能长生。是以圣人后其身而身先，外其身而身存。非以其无私耶？故能成其私。(后其身 一作：退其身)\n 天地长久，不自生：天地不是单一的生命，以万物的生命来体现自己的生命。万物演变恒久不息，天也恒久存在。\n是以圣人后其身而身先，外其身而身存： 老子对后代人物的政治谋略影响较大，怎么在政治上立于不败之地。看上去是哲理，但用起来是技巧。\n 四十章：反者道之动；弱者道之用。天下万物生于有，有生于无。 老子要否认所有提升到“规则”层面的内容。\n  二章：天下皆知美之为美，斯恶已。皆知善之为善，斯不善已。故有无相生，难易相成，长短相形，高下相倾，音声相和，前后相随，恒也。是以圣人处无为之事，行不言之教，万物作焉而不辞，生而不有，为而不恃，功成而弗居。夫唯弗居，是以不去。(万物作焉而不辞 一作：万物作焉而不为始)\n 理解：古人淳朴自然的理解中没有“美”的概念，其为认为的\n讲的是常识中相对的概念的相互转化。\n道：不是规律性 充满辩证的因果关系？不能说不对，但是容易被误导。辩证法、辩证规律本质上都还是对我们知识的概括。第一层：形式逻辑；第二层：变化规律、辩证法。顺着这个理解\n 五十八章：祸兮福所倚；福兮祸所伏。孰知其极？其无正邪？正复为奇，善复为妖。人之迷，其日固久。\n  极：根本的道理。“悠悠苍天，曷其有极？” 无正：没有规则、根本道理。 奇：突然冒出来的、没有道理的 妖：怪异的  根本上否定规律性，而不是相反相成。 不应当将道理解为规律\n 道可道，非常道；名可名，非常名。无名天地之始，有名万物之母。\n  第二个“道”：  言说 走路：明明白白的路径   天地之始 万物之母：天地初始的状态  有关天地起源问题：  谷神不死，是谓玄牝。玄牝之门，是谓天地根。绵绵若存，用之不勤。\n  谷神：道 玄牝：雌性的牲畜，有学者由此将老子思想归结于民间崇拜  颜世安老师想法：可能受到淮河水网地区地方信仰的影响：水崇拜、雌性崇拜。但老子不停留在这个层面，而是提出了一种思想。 此处将道与雌性生殖功能做类比     有物混成，先天地生，寂兮寥兮，独立而不改，周行而不殆，可以为天地母。吾不知其名，强字之曰道，强为之名曰大。\n  有物混成：道 周兴不殆在出土文献中均不存在，大概率是后人添加。   孔德之容，惟道是从。道之为物，惟恍惟惚。惚兮恍兮，其中有象；恍兮惚兮，其中有物；窈兮冥兮，其中有精；其精甚真，其中有信。\n 但老子的本意应当不是天地起源：\n 后世道家，天地起源不是道家思想的中心。庄子嘲笑天地起源的探究。 如果谈天地起源，为什么在文本中一直强调“说不清楚”，许多地方既有又无？“孰知其极”？  不要将道与天地起源混为一谈！\n原初状态 谈天地之道，应当从天地的原初状态谈起，对比原初状态和现在状态的对比。从而使得人回到自己“自然”、“原初”的状态，以天道为引导。\n 致虚极；守静笃。万物并作，吾以观复。夫物芸芸，各复归其根。归根曰静，静曰复命。复命曰常，知常曰明。不知常，妄作凶。知常容，容乃公，公乃全，全乃天，天乃道，道乃久，歿身不殆。\n  虚、静：心态意义上的原初状态  虚 对应：实、知识、成见 静 对应：好物、情感     为学日益，为道日损。损之又损，以至於无为。无为而无不为。\n  为道要一天天减少自己的知识，直至无有的状态。   不出户，知天下；不窥牖，见天道。其出弥远，其知弥少。\n  在经验意义上回到自己的状态。有经验便有成见。   知其雄，守其雌，为天下谿。为天下谿，常德不离，复归于婴儿。\n 只要是道家文献，必然谈回到原初状态\n理解自然之道 自己生、自己长，本来如此。与计划、规则相对。\n 古之人，其知有所至矣。恶乎生？有以为未始有物者，至矣，尽矣，不可以加矣。其次，以为有物矣，而未始有封也。其次以为有封焉，而未始有是非也。是非之彰也，道之所以亏也。道之所以亏，爱之所以成。\n  至：强？弱？总之不一样。 未始有物：物我一体  郭象：未始有我。无自我意识。   封：将物分为不同领域。 爱：偏私、喜好  人们悲惨的根源：人们生下来便不可避免地落入非自然的状态中。解决：回到原初状态。\n 道家无为，又曰无不为，其实易行，其辞难知。其术以虚无为本，以因循为用。\n  难知：天地初始状态，难以用现有的语言进行描述。思维习惯、语言、行为规范是禁锢、限制、不自由、不自然。描述初始状态时必然会用到玄奥的词句。 其实易行：回到初始状态  庄子：自由与自然的紧张。警惕“自我”对他人的毒害。\n","date":"2021-11-24T00:00:00Z","permalink":"https://comfluter.life/p/%E5%85%88%E7%A7%A6%E8%AF%B8%E5%AD%90%E9%80%89%E8%AF%BB%E9%81%93%E5%AE%B6%E6%80%9D%E6%83%B3/","title":"《先秦诸子选读》：道家思想"},{"content":"Conda 复制已有环境 由于服务器上本身已经有使用CUDA平台的ToD-BERT运行环境，仅需将此环境中所有使用GPU的库换为使用CPU的库即可：pytorch\n查看已有环境\n(base) dialogue@amax-13:/$ conda info --env # conda environments: # base * /media/HD1/dche/miniconda3 sum_env /media/HD1/dche/miniconda3/envs/sum_env tod_bert /media/HD1/dche/miniconda3/envs/tod_bert /media/HD1/miniconda3 创建新环境，并将原有环境中的所有包复制，并激活新建立的环境。\n(base) dialogue@amax-13:/$ conda create -n tod_bert_cpu --clone tod_bert Source: /media/HD1/dche/miniconda3/envs/tod_bert Destination: /media/HD1/dche/miniconda3/envs/tod_bert_cpu Packages: 20 Files: 12683 Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate tod_bert_cpu # # To deactivate an active environment, use # # $ conda deactivate (base) dialogue@amax-13:/$ conda activate tod_bert_cpu (tod_bert_cpu) dialogue@amax-13:/$ Conda配置环境中的包（卸载GPU版本、安装CPU版本） Conda 查看环境中所有包的信息\n(tod_bert_cpu) dialogue@amax-13:/$ conda list # packages in environment at /media/HD1/dche/miniconda3/envs/tod_bert_cpu: # # Name Version Build Channel _libgcc_mutex 0.1 main _openmp_mutex 4.5 1_gnu anykeystore 0.2 pypi_0 pypi apex 0.9.8.dev0 pypi_0 pypi blessings 1.7 pypi_0 pypi ca-certificates 2021.10.26 h06a4308_2 certifi 2021.10.8 py37h06a4308_0 charset-normalizer 2.0.7 pypi_0 pypi click 8.0.3 pypi_0 pypi cryptacular 1.6.2 pypi_0 pypi defusedxml 0.7.1 pypi_0 pypi filelock 3.4.0 pypi_0 pypi future 0.18.2 pypi_0 pypi gpustat 0.6.0 pypi_0 pypi greenlet 1.1.2 pypi_0 pypi hupper 1.10.3 pypi_0 pypi idna 3.3 pypi_0 pypi importlib-metadata 4.8.2 pypi_0 pypi joblib 1.1.0 pypi_0 pypi libedit 3.1.20210910 h7f8727e_0 libffi 3.2.1 hf484d3e_1007 libgcc-ng 9.3.0 h5101ec6_17 libgomp 9.3.0 h5101ec6_17 libstdcxx-ng 9.3.0 hd4cf53a_17 markupsafe 2.0.1 pypi_0 pypi ncurses 6.3 h7f8727e_2 nltk 3.5 pypi_0 pypi numpy 1.18.1 pypi_0 pypi nvidia-ml-py3 7.352.0 pypi_0 pypi oauthlib 3.1.1 pypi_0 pypi openssl 1.0.2u h7b6447c_0 packaging 21.3 pypi_0 pypi pastedeploy 2.1.1 pypi_0 pypi pbkdf2 1.3 pypi_0 pypi pip 21.2.2 py37h06a4308_0 plaster 1.0 pypi_0 pypi plaster-pastedeploy 0.7 pypi_0 pypi protobuf 3.19.1 pypi_0 pypi psutil 5.8.0 pypi_0 pypi ptvsd 4.3.2 pypi_0 pypi pyparsing 3.0.6 pypi_0 pypi pyramid 2.0 pypi_0 pypi pyramid-mailer 0.15.1 pypi_0 pypi python 3.7.0 h6e4f718_3 python3-openid 3.2.0 pypi_0 pypi readline 7.0 h7b6447c_5 regex 2021.11.10 pypi_0 pypi repoze-sendmail 4.4.1 pypi_0 pypi requests 2.26.0 pypi_0 pypi requests-oauthlib 1.3.0 pypi_0 pypi sacremoses 0.0.46 pypi_0 pypi scikit-learn 0.23.2 pypi_0 pypi scipy 1.7.2 pypi_0 pypi sentencepiece 0.1.96 pypi_0 pypi setuptools 58.0.4 py37h06a4308_0 simplejson 3.17.2 pypi_0 pypi six 1.15.0 pypi_0 pypi sqlalchemy 1.4.27 pypi_0 pypi sqlite 3.33.0 h62c20be_0 tensorboardx 2.1 pypi_0 pypi threadpoolctl 3.0.0 pypi_0 pypi tk 8.6.11 h1ccaba5_0 tokenizers 0.8.1rc1 pypi_0 pypi torch 1.6.0 pypi_0 pypi tqdm 4.31.1 pypi_0 pypi transaction 3.0.1 pypi_0 pypi transformers 3.0.2 pypi_0 pypi translationstring 1.4 pypi_0 pypi typing-extensions 4.0.0 pypi_0 pypi urllib3 1.26.7 pypi_0 pypi velruse 1.1.1 pypi_0 pypi venusian 3.0.0 pypi_0 pypi webob 1.8.7 pypi_0 pypi wheel 0.37.0 pyhd3eb1b0_1 wtforms 3.0.0 pypi_0 pypi wtforms-recaptcha 0.3.2 pypi_0 pypi xz 5.2.5 h7b6447c_0 zipp 3.6.0 pypi_0 pypi zlib 1.2.11 h7b6447c_3 zope-deprecation 4.4.0 pypi_0 pypi zope-interface 5.4.0 pypi_0 pypi zope-sqlalchemy 1.6 pypi_0 pypi 卸载原有的GPU版本torch，貌似原先是使用pip安装的，在尝试conda卸载无果后使用pip卸载成功。\n(tod_bert_cpu) dialogue@amax-13:/$ conda remove pytorch Collecting package metadata (repodata.json): done Solving environment: failed PackagesNotFoundError: The following packages are missing from the target environment: - pytorch (tod_bert_cpu) dialogue@amax-13:/$ pip uninstall torch Found existing installation: torch 1.6.0 Uninstalling torch-1.6.0: Would remove: /media/HD1/dche/miniconda3/envs/tod_bert_cpu/bin/convert-caffe2-to-onnx /media/HD1/dche/miniconda3/envs/tod_bert_cpu/bin/convert-onnx-to-caffe2 /media/HD1/dche/miniconda3/envs/tod_bert_cpu/lib/python3.7/site-packages/caffe2/* /media/HD1/dche/miniconda3/envs/tod_bert_cpu/lib/python3.7/site-packages/torch-1.6.0.dist-info/* /media/HD1/dche/miniconda3/envs/tod_bert_cpu/lib/python3.7/site-packages/torch/* Proceed (Y/n)? y Successfully uninstalled torch-1.6.0 安装cpu版本torch\n(tod_bert_cpu) dialogue@amax-13:/$ conda install pytorch==1.6.0 torchvision==0.7.0 cpuonly -c pytorch Collecting package metadata (current_repodata.json): done Solving environment: done ## Package Plan ## environment location: /media/HD1/dche/miniconda3/envs/tod_bert_cpu added / updated specs: - cpuonly - pytorch==1.6.0 - torchvision==0.7.0 The following packages will be downloaded: | package | build | | --------------------- | ----------------------------------- | | blas-1.0 | mkl 6 KB | | cpuonly-2.0 | 0 2 KB pytorch | | freetype-2.11.0 | h70c0345_0 618 KB | | giflib-5.2.1 | h7b6447c_0 78 KB | | intel-openmp-2021.4.0 | h06a4308_3561 4.2 MB | | jpeg-9d | h7f8727e_0 232 KB | | lcms2-2.12 | h3be6417_0 312 KB | | libpng-1.6.37 | hbc83047_0 278 KB | | libtiff-4.2.0 | h85742a9_0 502 KB | | libwebp-1.2.0 | h89dd481_0 493 KB | | libwebp-base-1.2.0 | h27cfd23_0 437 KB | | lz4-c-1.9.3 | h295c915_1 185 KB | | mkl-2021.4.0 | h06a4308_640 142.6 MB | | mkl-service-2.4.0 | py37h7f8727e_0 56 KB | | mkl_fft-1.3.1 | py37hd3c417c_0 172 KB | | mkl_random-1.2.2 | py37h51133e4_0 287 KB | | ninja-1.10.2 | py37hd09550d_3 1.5 MB | | numpy-1.21.2 | py37h20f2e39_0 23 KB | | numpy-base-1.21.2 | py37h79a1101_0 4.8 MB | | olefile-0.46 | py37_0 50 KB | | pillow-8.4.0 | py37h5aabda8_0 644 KB | | pytorch-1.6.0 | py3.7_cpu_0 59.4 MB pytorch | | pytorch-mutex-1.0 | cpu 3 KB pytorch | | torchvision-0.7.0 | py37_cpu 10.3 MB pytorch | | zstd-1.4.9 | haebb681_0 480 KB | ------------------------------------------------------------ Total: 227.4 MB The following NEW packages will be INSTALLED: blas pkgs/main/linux-64::blas-1.0-mkl cpuonly pytorch/noarch::cpuonly-2.0-0 freetype pkgs/main/linux-64::freetype-2.11.0-h70c0345_0 giflib pkgs/main/linux-64::giflib-5.2.1-h7b6447c_0 intel-openmp pkgs/main/linux-64::intel-openmp-2021.4.0-h06a4308_3561 jpeg pkgs/main/linux-64::jpeg-9d-h7f8727e_0 lcms2 pkgs/main/linux-64::lcms2-2.12-h3be6417_0 libpng pkgs/main/linux-64::libpng-1.6.37-hbc83047_0 libtiff pkgs/main/linux-64::libtiff-4.2.0-h85742a9_0 libwebp pkgs/main/linux-64::libwebp-1.2.0-h89dd481_0 libwebp-base pkgs/main/linux-64::libwebp-base-1.2.0-h27cfd23_0 lz4-c pkgs/main/linux-64::lz4-c-1.9.3-h295c915_1 mkl pkgs/main/linux-64::mkl-2021.4.0-h06a4308_640 mkl-service pkgs/main/linux-64::mkl-service-2.4.0-py37h7f8727e_0 mkl_fft pkgs/main/linux-64::mkl_fft-1.3.1-py37hd3c417c_0 mkl_random pkgs/main/linux-64::mkl_random-1.2.2-py37h51133e4_0 ninja pkgs/main/linux-64::ninja-1.10.2-py37hd09550d_3 numpy pkgs/main/linux-64::numpy-1.21.2-py37h20f2e39_0 numpy-base pkgs/main/linux-64::numpy-base-1.21.2-py37h79a1101_0 olefile pkgs/main/linux-64::olefile-0.46-py37_0 pillow pkgs/main/linux-64::pillow-8.4.0-py37h5aabda8_0 pytorch pytorch/linux-64::pytorch-1.6.0-py3.7_cpu_0 pytorch-mutex pytorch/noarch::pytorch-mutex-1.0-cpu six pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_0 torchvision pytorch/linux-64::torchvision-0.7.0-py37_cpu zstd pkgs/main/linux-64::zstd-1.4.9-haebb681_0 Proceed ([y]/n)? y Downloading and Extracting Packages olefile-0.46 | 50 KB | ############################################################################################# | 100%  numpy-base-1.21.2 | 4.8 MB | ############################################################################################# | 100%  libpng-1.6.37 | 278 KB | ############################################################################################# | 100%  freetype-2.11.0 | 618 KB | ############################################################################################# | 100%  libwebp-base-1.2.0 | 437 KB | ############################################################################################# | 100%  blas-1.0 | 6 KB | ############################################################################################# | 100%  libtiff-4.2.0 | 502 KB | ############################################################################################# | 100%  torchvision-0.7.0 | 10.3 MB | ############################################################################################# | 100%  zstd-1.4.9 | 480 KB | ############################################################################################# | 100%  pytorch-1.6.0 | 59.4 MB | ############################################################################################# | 100%  libwebp-1.2.0 | 493 KB | ############################################################################################# | 100%  jpeg-9d | 232 KB | ############################################################################################# | 100%  intel-openmp-2021.4. | 4.2 MB | ############################################################################################# | 100%  lcms2-2.12 | 312 KB | ############################################################################################# | 100%  mkl-service-2.4.0 | 56 KB | ############################################################################################# | 100%  pytorch-mutex-1.0 | 3 KB | ############################################################################################# | 100%  giflib-5.2.1 | 78 KB | ############################################################################################# | 100%  mkl_random-1.2.2 | 287 KB | ############################################################################################# | 100%  cpuonly-2.0 | 2 KB | ############################################################################################# | 100%  mkl-2021.4.0 | 142.6 MB | ############################################################################################# | 100%  ninja-1.10.2 | 1.5 MB | ############################################################################################# | 100%  mkl_fft-1.3.1 | 172 KB | ############################################################################################# | 100%  pillow-8.4.0 | 644 KB | ############################################################################################# | 100%  lz4-c-1.9.3 | 185 KB | ############################################################################################# | 100%  numpy-1.21.2 | 23 KB | ############################################################################################# | 100%  Preparing transaction: done Verifying transaction: done Executing transaction: done 配置并运行BERT 直接使用同CPU的命令CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets，貌似没有任何问题地跑起来了？\n由于项目要求，需要限制模型使用cpu的核数。\n使用命令top -d 1查看目前cpu占用情况，顺便查看跑BERT模型的python进程PID\n使用命令taskset -cp \u0026lt;cpu list\u0026gt; \u0026lt;pid\u0026gt;进行绑核操作，ep.taskset -cp 0,1,2,3 94434\nReference Anaconda-用conda创建python虚拟环境\n","date":"2021-11-24T00:00:00Z","permalink":"https://comfluter.life/p/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEcpu%E7%89%88tod-bert%E7%8E%AF%E5%A2%83/","title":"服务器配置CPU版ToD-BERT环境"},{"content":"安装OpenCV Python中使用pip安装时的命令为pip install opencv-python\n(.venv) PS D:\\Work\\04 Research Project\\21.08.19 Early Visual Processing\\pyspice\u0026gt; pip install opencv-python Collecting opencv-python Downloading opencv_python-4.5.4.60-cp39-cp39-win_amd64.whl (35.1 MB) |████████████████████████████████| 35.1 MB 1.3 MB/s Requirement already satisfied: numpy\u0026gt;=1.19.3 in c:\\programming\\python\\lib\\site-packages (from opencv-python) (1.21.2) Installing collected packages: opencv-python Successfully installed opencv-python-4.5.4.60 导入时使用语句import cv2 as cv\n图像读取、显示与保存 import cv2 as cv imagePath = \u0026#34;D:\\\\Work\\\\04 Research Project\\\\21.08.19 Early Visual Processing\\\\pyspice\\\\assets\\\\img\\\\test.jpg\u0026#34; img = cv.imread(imagePath) # 读取图像 print(img) # 命令行打印图像像素信息 cv.imshow(\u0026#34;Display window\u0026#34;, img) # 调用窗口显示图像 k = cv.waitKey(0) # 在argument规定的时间内等待用户输入，并返回用户输入值，0=forever if k == ord(\u0026#34;s\u0026#34;): cv.imwrite( \u0026#34;D:\\\\Work\\\\04 Research Project\\\\21.08.19 Early Visual Processing\\\\pyspice\\\\assets\\\\img\\\\saved.jpg\u0026#34;, img) # 保存图像 cv.imread()参数：\n filename：读取图像的文件路径和文件名 flags：读取图片的方式，可选项  cv.IMREAD_COLOR(1)：始终将图像转换为 3 通道BGR彩色图像，默认方式 cv.IMREAD_GRAYSCALE(0)：始终将图像转换为单通道灰度图像 cv.IMREAD_UNCHANGED(-1)：按原样返回加载的图像（使用Alpha通道） cv.IMREAD_ANYDEPTH(2)：在输入具有相应深度时返回16位/ 32位图像，否则将其转换为8位 cv.IMREAD_ANYCOLOR(4)：以任何可能的颜色格式读取图像   返回值 retval：读取的 OpenCV 图像，nparray 多维数组  图像路径中不能有中文字符。\n读取并修改图像信息  图片像素信息：通过img = cv.imread(imagePath)读取得到的img类型为np.ndarray，其中0维为行数，1维为列数，2，3，4维分别为图片每像素B、G、R对应的值。注意顺序！ 图片大小信息：img.shape对象，为三值数组，分别为行数、列数、通道数。e.p.(138, 200, 3)  读取视频、调用摄像头、保存视频 import cv2 cap = cv2.VideoCapture(0) fourcc = cv2.VideoWriter_fourcc(*\u0026#39;XVID\u0026#39;) out = cv2.VideoWriter(\u0026#39;output.avi\u0026#39;, fourcc, 20.0, (640, 480)) while(cap.isOpened()): ret, frame = cap.read() out.write(frame) cv2.imshow(\u0026#39;frame\u0026#39;, frame) if cv2.waitKey(1) \u0026amp; 0xFF == ord(\u0026#39;q\u0026#39;): break cap.release() out.release() cv2.destroyAllWindows() 关键点：\n 调用摄像头：cap = cv2.VideoCapture(0) 创建一个VideoCapture对象。它的参数可以是设备索引或视频文件的名称（下面会讲到）。设备索引只是指定哪台摄像机的号码。0代表第一台摄像机、1代表第二台摄像机。之后，可以逐帧捕捉视频。最后释放捕获。 读取视频：cap = cv2.VideoCapture('\u0026lt;path to video\u0026gt;')，然后可以使用cap.isOpened()检查视频的打开情况 读取视频：= cv.VideoWriter( filename, fourcc, fps, frameSize[, isColor] )  filename：给要保存的视频起个名字 fourcc：指定视频编解码器的4字节代码 【（‘P’，‘I’，‘M’，‘1’）是MPEG-1编解码器】？ 【（‘M’，‘J’，‘P’，\u0026lsquo;G \u0026lsquo;）是一个运动jpeg编解码器】？ fps：帧率 frameSize：帧大小 isColor：如果为true，则视频为彩色，否则为灰度视频，默认为true   读取下一帧：ret, frame = cap.read() 将帧写到文件中：ret, frame = cap.read()  常用视频相关函数  cv2.VideoCapture.get(propId) 访问视频的某些功能，其中propId是一个从0到18的数字，每个数字表示视频的属性（Property Identifier）。 retval = cv2.VideoCapture.set(propId,value) 其中一些值可以使用 cap.set(propId，value) 进行修改，value是修改后的值。  例如：通过cap.get(3)和cap.get(4)来检查帧的宽度和高度，默认的值是640x480。现修改为320x240，使用ret = cap.set（3, 320）和ret = cap.set（4, 240）。   retval,image= cv2.VideoCapture.read([,image]) 抓取，解码并返回下一个视频帧。返回值为true表明抓取成功。该函数是组合了grab()和retrieve() ，这是最方便的方法。如果没有帧，该函数返回false，并输出空图像。 retval, image = cv2.VideoCapture.retrieve([, image[, flag]]) 解码并返回抓取的视频帧 retval = cv2.VideoCapture.grab() 从视频文件或相机中抓取下一帧。true为抓取成功。该函数主要用于多摄像头时。 cv2.VideoCapture.release() 关闭视频文件或相机设备。  Reference 【OpenCV】Python视频的读取及保存\n","date":"2021-11-23T00:00:00Z","permalink":"https://comfluter.life/p/opencv-with-python/","title":"OpenCV with Python"},{"content":"数组切片 import numpy as np a = np.array([[11, 12, 13], [21, 22, 23]], [31, 32, 33]) 注意Numpy中元素编号从0开始，左侧包含右侧不包含\n 取单个元素x = a[1, 2]，对应第0维的第1个元素4 切片x = a[0:2, 1:3]，对应第0维的第0~1个元素，第1维的第1~2个元素[[12 13], [22 23]] 切片x = a[:2, 2:]，对应对应第0维的最开始到第2（2-1）个元素，第1维的第2个及以后的所有元素[[13], [23]]  判断一个数组是否存在于另一个大数组内 直接使用==会逐数字判断元素是否存在：\nimport numpy as np a = np.array([[1, 2, 3], [2, 3, 4]]) print(a == np.array([1, 2, 3])) 可以改为(a == np.array([1, 2, 3])).all(1).any()。y == z会将y的每一行与z的每个元素进行比较。 使用all(axis=1)可以获取所有元素匹配的行，并使用any()找出是否匹配。\nimport numpy as np a = np.array([[1, 2, 3], [2, 3, 4]]) print(a == np.array([1, 2, 3])) print((a == np.array([1, 2, 3])).all(1)) print((a == np.array([1, 2, 3])).all(1).any()) 输出结果：\n[[ True True True] [False False False]] [ True False] True 各种拷贝  无拷贝a = b:a,b完全相同，指向同一对象 浅拷贝b = a.view()：只会copy父对象，不会copy底层的数据，共用原始引用指向的对象数据。如果在view上修改数据，会直接反馈到原始对象。改变b的shape等父对象的参数时，不会改变a的相应参数 深拷贝b = a.copy()：对象及其子对象都进行copy一份，两对象完全独立。  ","date":"2021-11-22T00:00:00Z","permalink":"https://comfluter.life/p/numpy-%E5%AD%A6%E4%B9%A0%E9%9A%8F%E8%AE%B0/","title":"Numpy 学习随记"},{"content":"PlantUML with VsCode  Install PlantUML extension for vscode. following extension follow me document:  install java JRE install Graphviz download the latest plantuml.jar specify the jar location with the extension setting plantuml.jar specify the GraphViz installation by defining the Windows environment variable GRAPHVIZ_DOT, e.g., c:\\program files\\graphviz\\bin\\dot.exe    ","date":"2021-11-22T00:00:00Z","permalink":"https://comfluter.life/p/plantuml-%E5%AD%A6%E4%B9%A0%E9%9A%8F%E8%AE%B0/","title":"PlantUML 学习随记"},{"content":"Python Module Python Module 导入方法  import \u0026lt;module name\u0026gt;调用这个方法导入的module中的函数时，需要\u0026lt;module name\u0026gt;.\u0026lt;function name\u0026gt;格式进行使用 from \u0026lt;module name\u0026gt; import \u0026lt;sth\u0026gt;从某个模块中引入某些特殊函数等引入现在所在的全局命名空间中，直接使用\u0026lt;sth\u0026gt;就可以进行使用。这里引入的可以是一个子包，也可以是子包中的任意对象。 from \u0026lt;module name\u0026gt; import *将模块中所有对象引入，直接使用原模块中的名称即可使用  搜索路径 导入一个模块时，Python 解析器对模块位置的搜索顺序是：\n 当前目录 如果不在当前目录，Python 则搜索在 shell 变量 PYTHONPATH 下的每个目录。 如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/。 模块搜索路径存储在 system 模块的 sys.path 变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录。  命名空间和作用域  变量：名字与匹配对象的对应 命名空间：记录了所有名字-对象对应关系的字典  python表达式可以访问全局/局部命名空间，重名时局部命名空间优先。 使用global语句可以告诉python变量属于全局变量。ex.global x\n导入本地自定义包 文件结构\nmain.py package |--__init__.py |--module1.py |--module2.py 包是一个分层次的文件目录结构，它定义了一个由模块及子包，和子包下的子包等组成的 Python 的应用环境。\n简单来说，包就是文件夹，但该文件夹下必须存在__init__.py 文件, 该文件的内容可以为空。__init__.py 用于标识当前文件夹是一个包。\n假设module1.py中有函数func1()，则在main函数中可以使用以下集中方式进行包导入：\n import mymodule.module1此时对应func1()的调用为mymodule.module1.func1()，前缀较长，比较繁琐。 import mymodule.module1 as m1此时对应func1()的调用为m1.func1() from mymodule import module1此时对应func1()的调用为module1.func1()  集合数据类型 Python 编程语言中有四种集合数据类型：\n 列表（List）是一种有序和可更改的集合。允许重复的成员。 元组（Tuple）是一种有序且不可更改的集合。允许重复的成员。 集合（Set）是一个无序和无索引的集合。没有重复的成员。 词典（Dictionary）是一个无序，可变和有索引的集合。没有重复的成员。  选择集合类型时，了解该类型的属性很有用。\n为特定数据集选择正确的类型可能意味着保留含义，并且可能意味着提高效率或安全性。\n List  thislist = [\u0026quot;apple\u0026quot;, \u0026quot;banana\u0026quot;, \u0026quot;cherry\u0026quot;] print(thislist[1]) thislist[1] = \u0026quot;mango\u0026quot;   Tuple  thistuple = (\u0026quot;apple\u0026quot;, \u0026quot;banana\u0026quot;, \u0026quot;cherry\u0026quot;) print(thistuple[1]) 不可更改，需要转为列表更改后再转回   Set  thisset = {\u0026quot;apple\u0026quot;, \u0026quot;banana\u0026quot;, \u0026quot;cherry\u0026quot;} 访问项目：  您无法通过引用索引来访问 set 中的项目，因为 set 是无序的，项目没有索引。 但是您可以使用 for 循环遍历 set 项目，或者使用 in 关键字查询集合中是否存在指定值。   要将一个项添加到集合，请使用 add() 方法。 要向集合中添加多个项目，请使用 update() 方法。   Dictionary  创建字典 thisdict =\t{ \u0026#34;brand\u0026#34;: \u0026#34;Porsche\u0026#34;, \u0026#34;model\u0026#34;: \u0026#34;911\u0026#34;, \u0026#34;year\u0026#34;: 1963 }  x = thisdict[\u0026quot;model\u0026quot;] or x = thisdict.get(\u0026quot;model\u0026quot;) thisdict[\u0026ldquo;year\u0026rdquo;] = 2019    Virtual Environment 安装虚拟环境 PS D:\\Work\\04 Research Project\\21.08.19 Early Visual Processing\\pyspice\u0026gt; pip install virtualenv Collecting virtualenv |████████████████████████████████| 5.6 MB 6.4 MB/s Collecting filelock\u0026lt;4,\u0026gt;=3.2 Downloading filelock-3.4.0-py3-none-any.whl (9.8 kB) Collecting backports.entry-points-selectable\u0026gt;=1.0.4 Downloading backports.entry_points_selectable-1.1.1-py2.py3-none-any.whl (6.2 kB) Collecting platformdirs\u0026lt;3,\u0026gt;=2 Downloading platformdirs-2.4.0-py3-none-any.whl (14 kB) Collecting distlib\u0026lt;1,\u0026gt;=0.3.1 |████████████████████████████████| 496 kB 1.6 MB/s Requirement already satisfied: six\u0026lt;2,\u0026gt;=1.9.0 in c:\\programming\\python\\lib\\site-packages (from virtualenv) (1.16.0) Installing collected packages: platformdirs, filelock, distlib, backports.entry-points-selectable, virtualenv 创建虚拟环境 virtualenv myvenv，可选参数：\n --no-site-packages：创建虚拟环境时，不复制主环境中安装的第三方包，也就是创建一个 “干净的” 虚拟环境 -p：用于指定 Python 解析器，就是安装好的 Python 应用程序，默认为当前环境中的 Python --no-pip：不需要安装 pip，默认为安装 --clear：如果创建虚拟环境的目录已经有了其他虚拟环境，清除重建  激活虚拟环境 虚拟环境创建好后，需要激活才能在当前命令行中使用，可以理解成将当前命令行环境中 PATH 变量的值替换掉\n通过 virtualenv 和 模块 venv 创建的虚拟环境，激活方式是一样的，即运行激活脚本\n Windows 系统中，激活脚本路径是 \u0026lt;myvenv\u0026gt;\\Scripts\\activate.bat，如果是 powershell 命令行，脚本换成 Activate.ps1 , 注意将 换成你自己的虚拟环境目录 Linux 系统中，激活脚本路径是 \u0026lt;myvenv\u0026gt;/bin/activate，默认脚本没有执行权限，要么设置脚本为可执行，要么用 source 命令执行  激活后，可以查看PATH变量 echo %PATH%\n退出虚拟环境 退出虚拟环境很简单，只需要执行 deactivate 命令就行，这个命令也在虚拟环境的脚本目录下，因为激活时，将脚本目录设置到 PATH 中了，所以可以直接使用\n退出虚拟环境相当于将 PATH 恢复成原来的\nMinutiae  Python does not have switch statement. Use dict instead. autopep8 auto line feed:  Python编码风格指导(PEP8)要求每行代码不得超过80个字符。而VSCode+Pyhon常用代码检查工具是pylint和flake8，常用代码格式化工具是yapf、autopep8和black。针对代码过长导致格式化时自动换行，应在setting.json中修改格式化工具的每行最大字符个数。 // autopep8 \u0026quot;python.formatting.provider\u0026quot;: \u0026quot;autopep8\u0026quot;, \u0026quot;python.formatting.autopep8Args\u0026quot;: [ \u0026quot;--max-line-length=200\u0026quot; ],    exec 执行储存在字符串或文件中的 Python 语句，相比于 eval，exec可以执行更复杂的 Python 代码  Resources (W3School Python 教程)[https://www.w3school.com.cn/python/index.asp]\n","date":"2021-11-22T00:00:00Z","permalink":"https://comfluter.life/p/python-%E5%AD%A6%E4%B9%A0%E9%9A%8F%E8%AE%B0/","title":"Python 学习随记"},{"content":"问题  设备选择：  主要参数：内存 GPU 设备：jetson更好  树莓派算力有限，人工智能框架支持不官方 jetson有关方支持 tensor+树莓派能媲美jetson+tensor IO口     Tod-BERT fine tune  精调后的inference time \u0026amp; 内存占用？   ToD-inference time 单位？  任务  树莓派装pytorch ToD-BERT 在树莓派上训练、推理 ToD-BERT fine tune ToD-BERT inference time  想测在一个卡上batch size = 1时候的推理时间 cuda.event时间数值的单位？ time包中测出来的时间？ 10ms级别 使用time包测量的方法        服务器CPU运行测量 training  限制CPU核心数量4 batch size = 1，2，4 重新配置conda环境，安装CPU版本pytorch  配置conda环境教程   用time模块测量   立项答辩  突出动机 抓住评委兴趣 语速、文字减少，减少技术细节 突出重音、重点 每人提2条意见 应用场景 边缘端部署  内存需求 算力需求      ","date":"2021-11-22T00:00:00Z","permalink":"https://comfluter.life/p/%E5%A4%A7%E5%88%9B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F21.11.22%E7%BB%84%E4%BC%9A/","title":"大创对话系统21.11.22组会"},{"content":"在服务器上运行ToD-BERT训练  进入服务器，激活环境source activate todbert_env 进入/media/HD1/dche/ToD-BERT文件夹cd /media/HD1/dche/ToD-BERT 查看GPU资源占用情况nvidia-smi，然后选择目前占用情况较低的一张GPU进行训练即可 运行训练shell脚本文件CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets。根据第三步选择的几号卡，就把对应的0改成几，此处默认单卡训练。如果一切正常的话，再读入数据集数据后，就会开始训练了，有进度条出现就Ok了。常见的没跑起来的情况是CUDA out of memory。  ToD-BERT本地调用  将ToD-BERT模型下载至本地 包含ToD-BERT所需的python包，并定义模型路径 import torch from transformers import * BERT = \u0026lt;path_to_the_downloaded_tod-bert\u0026gt; # 注意此处的路径要使用从根目录开始的绝对路径，而非从用户~目录开始的相对路径。 model_class, tokenizer_class, config_class = BertModel, BertTokenizer, BertConfig tokenizer = tokenizer_class.from_pretrained(BERT) tod_bert = model_class.from_pretrained(BERT)  使用ToD-BERT文档中的示例 # Encode text  input_text = \u0026#34;[CLS] [SYS] Hello, what can I help with you today? [USR] Find me a cheap restaurant nearby the north town.\u0026#34; input_tokens = tokenizer.tokenize(input_text) story = torch.Tensor(tokenizer.convert_tokens_to_ids(input_tokens)).long() if len(story.size()) == 1: story = story.unsqueeze(0) # batch size dimension if torch.cuda.is_available(): tod_bert = tod_bert.cuda() story = story.cuda() with torch.no_grad(): input_context = {\u0026#34;input_ids\u0026#34;: story, \u0026#34;attention_mask\u0026#34;: (story \u0026gt; 0).long()} hiddens = tod_bert(**input_context)[0]   计算ToD-BERT推理时间延迟 如何正确地计算 深度学习中如何正确地measure inference time\n问题：\n 在进行多batch训练或推理的时候，batch1被送进GPU后，CPU由于异步执行，不再等待batch1在GPU内执行完毕，而是直接对batch2进行预处理，此时若使用python的time库，停止计算时间的代码将在GPU执行完毕前被执行，导致时长计算错误。 GPU在不工作时将关掉许多硬件模块，在调用GPU时需要重新初始化（GPU预热），占用大量时间，导致时间测算错误。  解决方法：\n 在真正需要的example前运行几个example，使得GPU不再处于省电模式。 使用tr.cuda.event，在GPU上测量时间 使用函数torch.cuda.synchronize()，使得CPU和GPU工作在同步执行模式。  在服务器上进行inference并计算inference时间   在run_tod_lm_pretraining.sh文件中修改batch size = 1:\ngpu=$1 model_type=$2 bert_dir=$3 output_dir=$4 add1=$5 add2=$6 add3=$7 add4=$8 add5=$9 # ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn # ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-JNT --only_last_turn --add_rs_loss CUDA_VISIBLE_DEVICES=3 python my_tod_pretraining.py \\  --task=usdl \\  --model_type=${model_type} \\  --model_name_or_path=${bert_dir} \\  --output_dir=${output_dir} \\  --do_train \\  --do_eval \\  --mlm \\  --do_lower_case \\  --evaluate_during_training \\  --save_steps=2500 --logging_steps=1000 \\  --per_gpu_train_batch_size=1 --per_gpu_eval_batch_size=1 \\  ${add1} ${add2} ${add3} ${add4} ${add5}   使用上文办法，在my_tod_pretraining.py中引入计时相关语句：\n## with only MLM loss else: starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True) inputs = batch[\u0026#34;context\u0026#34;].clone() if args.mlm: inputs, labels = mask_tokens(inputs, tokenizer, args) inputs = inputs.to(args.device) labels = labels.to(args.device) starter.record() outputs = model(inputs, masked_lm_labels=labels, attention_mask=inputs\u0026gt;0) ender.record() # WAIT FOR GPU SYNC torch.cuda.synchronize() curr_time = starter.elapsed_time(ender) print(curr_time)   由于训练时间较长，使用tmux命令：tmux new -s inference_time_measure，进入tmux回话后还需要重新激活虚拟环境。\n\\(base) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/prtrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets Traceback (most recent call last): File \u0026#34;/media/HD1/dche/ToD-BERT/my_tod_pretraining.py\u0026#34;, line 16, in \u0026lt;module\u0026gt; import numpy as np ModuleNotFoundError: No module named \u0026#39;numpy\u0026#39; (base) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ conda info --env # conda environments: # base * /media/HD1/dche/miniconda3 sum_env /media/HD1/dche/miniconda3/envs/sum_env tod_bert /media/HD1/dche/miniconda3/envs/tod_bert /media/HD1/miniconda3 (base) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ conda activate tod_bert (tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets   进行训练，观察输出结果 CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets\n  训练过程中可以使用crtl+b d从会话中分离\n(tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ tmux new -s inference_time_measure [detached (from session inference_time_measure)] (tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$   可以查看当前的tmux会话并连接\n(tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ tmux ls inference_time_measure: 1 windows (created Sun Nov 21 23:26:48 2021) [134x33] zym1: 1 windows (created Sun Nov 21 18:34:03 2021) [148x45] zym2: 1 windows (created Sun Nov 21 18:34:44 2021) [113x12] (tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ tmux attach -t inference_time_measure   为了便于记录inference time，可以将bash命令中的输出全部写入txt文件，script -a 1.txt，则之后shell中所有文字都将被记录在1.txt中。\n  ","date":"2021-11-21T00:00:00Z","permalink":"https://comfluter.life/p/tod-bert-%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/","title":"ToD-BERT 相关内容"},{"content":"申请证书 在腾讯云SSL证书界面申请即可，过程很快，十分钟就通知证书申请成功。\n下载证书并上传至云服务器 在腾讯云SSL证书面板，找到要部署网站的证书，点击右侧的下载按钮即可下载\n SSL证书面板 \nzip包文件结构：\n zip_struct \n由于使用Nginx服务器，需要使用的文件全部放在Nginx文件夹下：\n \n将这两个文件复制到服务器Nginx安装路径下，我服务器上的安装路径为/etc/nginx：\nroot@VM-24-3-ubuntu:/# mv /home/ubuntu/download/1_comfluter.life_bundle.crt /etc/nginx root@VM-24-3-ubuntu:/# mv /home/ubuntu/download/2_comfluter.life.key /etc/nginx root@VM-24-3-ubuntu:/# cd /etc/nginx root@VM-24-3-ubuntu:/etc/nginx# ll -s total 80 4 drwxr-xr-x 8 root root 4096 Nov 21 10:05 ./ 4 drwxr-xr-x 115 root root 4096 Nov 15 15:50 ../ 4 -rw-rw-r-- 1 ubuntu ubuntu 3921 Nov 21 08:37 1_comfluter.life_bundle.crt 4 -rw-rw-r-- 1 ubuntu ubuntu 1700 Nov 21 08:37 2_comfluter.life.key 4 drwxr-xr-x 2 root root 4096 Nov 15 16:48 conf.d/ 4 -rw-r--r-- 1 root root 1077 Feb 4 2019 fastcgi.conf 4 -rw-r--r-- 1 root root 1007 Feb 4 2019 fastcgi_params 4 -rw-r--r-- 1 root root 2837 Feb 4 2019 koi-utf 4 -rw-r--r-- 1 root root 2223 Feb 4 2019 koi-win 4 -rw-r--r-- 1 root root 3957 Feb 4 2019 mime.types 4 drwxr-xr-x 2 root root 4096 May 26 01:10 modules-available/ 4 drwxr-xr-x 2 root root 4096 Nov 15 15:50 modules-enabled/ 4 -rw-r--r-- 1 root root 1512 Nov 15 16:53 nginx.conf 4 -rw-r--r-- 1 root root 180 Feb 4 2019 proxy_params 4 -rw-r--r-- 1 root root 636 Feb 4 2019 scgi_params 4 drwxr-xr-x 2 root root 4096 Nov 15 16:40 sites-available/ 4 drwxr-xr-x 2 root root 4096 Nov 15 16:48 sites-enabled/ 4 drwxr-xr-x 2 root root 4096 Nov 15 15:50 snippets/ 4 -rw-r--r-- 1 root root 664 Feb 4 2019 uwsgi_params 4 -rw-r--r-- 1 root root 3071 Feb 4 2019 win-utf 编辑Nginx服务器配置 更改/etc/nginx/sites-enabled下服务器配置文件：\nserver { listen 443 ssl; #填写绑定证书的域名 server_name comfluter.life; #证书文件名称 ssl_certificate 1_comfluter.life_bundle.crt; #私钥文件名称 ssl_certificate_key 2_comfluter.life.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { #网站主页路径。此路径仅供参考，具体请您按照实际目录操作。 #例如，您的网站运行目录在/etc/www下，则填写/etc/www。 root /home/ubuntu/www/Blogs/Personal; index index.html index.htm; } } server { listen 80; #填写绑定证书的域名 server_name comfluter.life; #把http的域名请求转成https return 301 https://$host$request_uri; } 配置中前半部分为https网页服务，后半部分为将http请求重定向至https请求\n验证配置文件：\nroot@VM-24-3-ubuntu:/etc/nginx# nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful 重启Nginx服务器：nginx -s reload\nhttps访问！ 此时输入comfluter.life访问时即可看到已经是https连接\n \nDebugging 更改成为https连接后博客的搜索功能出现问题，浏览器提示提交的表单不安全并阻止了搜索表单的提交。问题在于没有更改hugo博客配置文件中的baseURL字段，将其改为baseurl: https://comfluter.life即可解决。\n","date":"2021-11-21T00:00:00Z","permalink":"https://comfluter.life/p/%E5%9C%A8nginx%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2ssl%E8%AF%81%E4%B9%A6/","title":"在Nginx服务器上部署SSL证书"},{"content":"21.11.22 锁链  香农-奈奎斯特采样定律 测量：测不准原理  高速成像：  STEAM：10e-10 second 时间分辨率 STAMP：10e-12 second 最先进：10e-15 second 接近电子转移过程的时长！      information in imaging  香农：硕士论文：信息学开山  做一些无聊的事？还是有自己独特的思考？    yes and no question How many questions (y/n) must you ask to ensure the color of the ball you have?\n 8 red balls? 4 red \u0026amp; 2 blue \u0026amp; 1 black \u0026amp; 1 white? 2 red \u0026amp; 2 blue \u0026amp; 2 black \u0026amp; 2 white?  香农信息熵 傅里叶变换的信息损失？\n 取傅里叶变换的过程中，可以有位深 二维傅里叶变换，可以通过幅度反演相位 取傅里叶变换再取反变换？相似度有多高？  SSMS   傅里叶变换过后低频信息密集，高频信息稀疏。  JPEG压缩：压缩低频信息，让步给高频信息\nSignal Sparsity 图像中不是每一个频率都要进行采样！可以抽出傅里叶变换中影响比较大的信息量。\n Compressive sensing  通过采样稀疏的键值信号，尽可能好地还原信号    ","date":"2021-11-21T00:00:00Z","permalink":"https://comfluter.life/p/%E9%87%8D%E5%90%AC%E6%88%90%E5%83%8F%E4%B8%96%E7%95%8C%E7%9A%84%E5%A5%87%E5%A2%83/","title":"重听《成像世界的奇境》"}]