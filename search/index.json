[{"content":"数组切片 import numpy as np a = np.array([[11, 12, 13], [21, 22, 23]], [31, 32, 33]) 注意Numpy中元素编号从0开始，左侧包含右侧不包含\n 取单个元素x = a[1, 2]，对应第0维的第1个元素4 切片x = a[0:2, 1:3]，对应第0维的第0~1个元素，第1维的第1~2个元素[[12 13], [22 23]] 切片x = a[:2, 2:]，对应对应第0维的最开始到第2（2-1）个元素，第1维的第2个及以后的所有元素[[13], [23]]  判断一个数组是否存在于另一个大数组内 直接使用==会逐数字判断元素是否存在：\nimport numpy as np a = np.array([[1, 2, 3], [2, 3, 4]]) print(a == np.array([1, 2, 3])) 可以改为(a == np.array([1, 2, 3])).all(1).any()。y == z会将y的每一行与z的每个元素进行比较。 使用all(axis=1)可以获取所有元素匹配的行，并使用any()找出是否匹配。\nimport numpy as np a = np.array([[1, 2, 3], [2, 3, 4]]) print(a == np.array([1, 2, 3])) print((a == np.array([1, 2, 3])).all(1)) print((a == np.array([1, 2, 3])).all(1).any()) 输出结果：\n[[ True True True] [False False False]] [ True False] True ","date":"2021-11-22T00:00:00Z","permalink":"https://comfluter.life/p/numpy-%E5%AD%A6%E4%B9%A0%E9%9A%8F%E8%AE%B0/","title":"Numpy 学习随记"},{"content":"Python Module Python Module 导入方法  import \u0026lt;module name\u0026gt;调用这个方法导入的module中的函数时，需要\u0026lt;module name\u0026gt;.\u0026lt;function name\u0026gt;格式进行使用 from \u0026lt;module name\u0026gt; import \u0026lt;sth\u0026gt;从某个模块中引入某些特殊函数等引入现在所在的全局命名空间中，直接使用\u0026lt;sth\u0026gt;就可以进行使用。这里引入的可以是一个子包，也可以是子包中的任意对象。 from \u0026lt;module name\u0026gt; import *将模块中所有对象引入，直接使用原模块中的名称即可使用  搜索路径 导入一个模块时，Python 解析器对模块位置的搜索顺序是：\n 当前目录 如果不在当前目录，Python 则搜索在 shell 变量 PYTHONPATH 下的每个目录。 如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/。 模块搜索路径存储在 system 模块的 sys.path 变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录。  命名空间和作用域  变量：名字与匹配对象的对应 命名空间：记录了所有名字-对象对应关系的字典  python表达式可以访问全局/局部命名空间，重名时局部命名空间优先。 使用global语句可以告诉python变量属于全局变量。ex.global x\n导入本地自定义包 文件结构\nmain.py package |--__init__.py |--module1.py |--module2.py 包是一个分层次的文件目录结构，它定义了一个由模块及子包，和子包下的子包等组成的 Python 的应用环境。\n简单来说，包就是文件夹，但该文件夹下必须存在__init__.py 文件, 该文件的内容可以为空。__init__.py 用于标识当前文件夹是一个包。\n假设module1.py中有函数func1()，则在main函数中可以使用以下集中方式进行包导入：\n import mymodule.module1此时对应func1()的调用为mymodule.module1.func1()，前缀较长，比较繁琐。 import mymodule.module1 as m1此时对应func1()的调用为m1.func1() from mymodule import module1此时对应func1()的调用为module1.func1()  ","date":"2021-11-22T00:00:00Z","permalink":"https://comfluter.life/p/python-%E5%AD%A6%E4%B9%A0%E9%9A%8F%E8%AE%B0/","title":"Python 学习随记"},{"content":"问题  设备选择：  主要参数：内存 GPU 设备：jetson更好  树莓派算力有限，人工智能框架支持不官方 jetson有关方支持 tensor+树莓派能媲美jetson+tensor IO口     Tod-BERT fine tune  精调后的inference time \u0026amp; 内存占用？   ToD-inference time 单位？  任务  树莓派装pytorch ToD-BERT 在树莓派上训练、推理 ToD-BERT fine tune ToD-BERT inference time  想测在一个卡上batch size = 1时候的推理时间 cuda.event时间数值的单位？ time包中测出来的时间？ 10ms级别 使用time包测量的方法        服务器CPU运行测量 training  限制CPU核心数量4 batch size = 1，2，4 重新配置conda环境，安装CPU版本pytorch  配置conda环境教程   用time模块测量   立项答辩  突出动机 抓住评委兴趣 语速、文字减少，减少技术细节 突出重音、重点 每人提2条意见 应用场景 边缘端部署  内存需求 算力需求      ","date":"2021-11-22T00:00:00Z","permalink":"https://comfluter.life/p/%E5%A4%A7%E5%88%9B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F21.11.22%E7%BB%84%E4%BC%9A/","title":"大创对话系统21.11.22组会"},{"content":"在服务器上运行ToD-BERT训练  进入服务器，激活环境source activate todbert_env 进入/media/HD1/dche/ToD-BERT文件夹cd /media/HD1/dche/ToD-BERT 查看GPU资源占用情况nvidia-smi，然后选择目前占用情况较低的一张GPU进行训练即可 运行训练shell脚本文件CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets。根据第三步选择的几号卡，就把对应的0改成几，此处默认单卡训练。如果一切正常的话，再读入数据集数据后，就会开始训练了，有进度条出现就Ok了。常见的没跑起来的情况是CUDA out of memory。  ToD-BERT本地调用  将ToD-BERT模型下载至本地 包含ToD-BERT所需的python包，并定义模型路径 import torch from transformers import * BERT = \u0026lt;path_to_the_downloaded_tod-bert\u0026gt; # 注意此处的路径要使用从根目录开始的绝对路径，而非从用户~目录开始的相对路径。 model_class, tokenizer_class, config_class = BertModel, BertTokenizer, BertConfig tokenizer = tokenizer_class.from_pretrained(BERT) tod_bert = model_class.from_pretrained(BERT)  使用ToD-BERT文档中的示例 # Encode text  input_text = \u0026#34;[CLS] [SYS] Hello, what can I help with you today? [USR] Find me a cheap restaurant nearby the north town.\u0026#34; input_tokens = tokenizer.tokenize(input_text) story = torch.Tensor(tokenizer.convert_tokens_to_ids(input_tokens)).long() if len(story.size()) == 1: story = story.unsqueeze(0) # batch size dimension if torch.cuda.is_available(): tod_bert = tod_bert.cuda() story = story.cuda() with torch.no_grad(): input_context = {\u0026#34;input_ids\u0026#34;: story, \u0026#34;attention_mask\u0026#34;: (story \u0026gt; 0).long()} hiddens = tod_bert(**input_context)[0]   计算ToD-BERT推理时间延迟 如何正确地计算 深度学习中如何正确地measure inference time\n问题：\n 在进行多batch训练或推理的时候，batch1被送进GPU后，CPU由于异步执行，不再等待batch1在GPU内执行完毕，而是直接对batch2进行预处理，此时若使用python的time库，停止计算时间的代码将在GPU执行完毕前被执行，导致时长计算错误。 GPU在不工作时将关掉许多硬件模块，在调用GPU时需要重新初始化（GPU预热），占用大量时间，导致时间测算错误。  解决方法：\n 在真正需要的example前运行几个example，使得GPU不再处于省电模式。 使用tr.cuda.event，在GPU上测量时间 使用函数torch.cuda.synchronize()，使得CPU和GPU工作在同步执行模式。  在服务器上进行inference并计算inference时间   在run_tod_lm_pretraining.sh文件中修改batch size = 1:\ngpu=$1 model_type=$2 bert_dir=$3 output_dir=$4 add1=$5 add2=$6 add3=$7 add4=$8 add5=$9 # ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn # ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-JNT --only_last_turn --add_rs_loss CUDA_VISIBLE_DEVICES=3 python my_tod_pretraining.py \\  --task=usdl \\  --model_type=${model_type} \\  --model_name_or_path=${bert_dir} \\  --output_dir=${output_dir} \\  --do_train \\  --do_eval \\  --mlm \\  --do_lower_case \\  --evaluate_during_training \\  --save_steps=2500 --logging_steps=1000 \\  --per_gpu_train_batch_size=1 --per_gpu_eval_batch_size=1 \\  ${add1} ${add2} ${add3} ${add4} ${add5}   使用上文办法，在my_tod_pretraining.py中引入计时相关语句：\n## with only MLM loss else: starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True) inputs = batch[\u0026#34;context\u0026#34;].clone() if args.mlm: inputs, labels = mask_tokens(inputs, tokenizer, args) inputs = inputs.to(args.device) labels = labels.to(args.device) starter.record() outputs = model(inputs, masked_lm_labels=labels, attention_mask=inputs\u0026gt;0) ender.record() # WAIT FOR GPU SYNC torch.cuda.synchronize() curr_time = starter.elapsed_time(ender) print(curr_time)   由于训练时间较长，使用tmux命令：tmux new -s inference_time_measure，进入tmux回话后还需要重新激活虚拟环境。\n\\(base) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/prtrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets Traceback (most recent call last): File \u0026#34;/media/HD1/dche/ToD-BERT/my_tod_pretraining.py\u0026#34;, line 16, in \u0026lt;module\u0026gt; import numpy as np ModuleNotFoundError: No module named \u0026#39;numpy\u0026#39; (base) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ conda info --env # conda environments: # base * /media/HD1/dche/miniconda3 sum_env /media/HD1/dche/miniconda3/envs/sum_env tod_bert /media/HD1/dche/miniconda3/envs/tod_bert /media/HD1/miniconda3 (base) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ conda activate tod_bert (tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets   进行训练，观察输出结果 CUDA_VISIBLE_DEVICES=0 ./run_tod_lm_pretraining.sh 0 bert bert-base-uncased save/pretrain/ToD-BERT-MLM --only_last_turn --data_path ./../dialog_datasets\n  训练过程中可以使用crtl+b d从会话中分离\n(tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ tmux new -s inference_time_measure [detached (from session inference_time_measure)] (tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$   可以查看当前的tmux会话并连接\n(tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ tmux ls inference_time_measure: 1 windows (created Sun Nov 21 23:26:48 2021) [134x33] zym1: 1 windows (created Sun Nov 21 18:34:03 2021) [148x45] zym2: 1 windows (created Sun Nov 21 18:34:44 2021) [113x12] (tod_bert) dialogue@amax-13:/media/HD1/dche/ToD-BERT$ tmux attach -t inference_time_measure   为了便于记录inference time，可以将bash命令中的输出全部写入txt文件，script -a 1.txt，则之后shell中所有文字都将被记录在1.txt中。\n  ","date":"2021-11-21T00:00:00Z","permalink":"https://comfluter.life/p/tod-bert-%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/","title":"ToD-BERT 相关内容"},{"content":"申请证书 在腾讯云SSL证书界面申请即可，过程很快，十分钟就通知证书申请成功。\n下载证书并上传至云服务器 在腾讯云SSL证书面板，找到要部署网站的证书，点击右侧的下载按钮即可下载\n SSL证书面板 \nzip包文件结构：\n zip_struct \n由于使用Nginx服务器，需要使用的文件全部放在Nginx文件夹下：\n \n将这两个文件复制到服务器Nginx安装路径下，我服务器上的安装路径为/etc/nginx：\nroot@VM-24-3-ubuntu:/# mv /home/ubuntu/download/1_comfluter.life_bundle.crt /etc/nginx root@VM-24-3-ubuntu:/# mv /home/ubuntu/download/2_comfluter.life.key /etc/nginx root@VM-24-3-ubuntu:/# cd /etc/nginx root@VM-24-3-ubuntu:/etc/nginx# ll -s total 80 4 drwxr-xr-x 8 root root 4096 Nov 21 10:05 ./ 4 drwxr-xr-x 115 root root 4096 Nov 15 15:50 ../ 4 -rw-rw-r-- 1 ubuntu ubuntu 3921 Nov 21 08:37 1_comfluter.life_bundle.crt 4 -rw-rw-r-- 1 ubuntu ubuntu 1700 Nov 21 08:37 2_comfluter.life.key 4 drwxr-xr-x 2 root root 4096 Nov 15 16:48 conf.d/ 4 -rw-r--r-- 1 root root 1077 Feb 4 2019 fastcgi.conf 4 -rw-r--r-- 1 root root 1007 Feb 4 2019 fastcgi_params 4 -rw-r--r-- 1 root root 2837 Feb 4 2019 koi-utf 4 -rw-r--r-- 1 root root 2223 Feb 4 2019 koi-win 4 -rw-r--r-- 1 root root 3957 Feb 4 2019 mime.types 4 drwxr-xr-x 2 root root 4096 May 26 01:10 modules-available/ 4 drwxr-xr-x 2 root root 4096 Nov 15 15:50 modules-enabled/ 4 -rw-r--r-- 1 root root 1512 Nov 15 16:53 nginx.conf 4 -rw-r--r-- 1 root root 180 Feb 4 2019 proxy_params 4 -rw-r--r-- 1 root root 636 Feb 4 2019 scgi_params 4 drwxr-xr-x 2 root root 4096 Nov 15 16:40 sites-available/ 4 drwxr-xr-x 2 root root 4096 Nov 15 16:48 sites-enabled/ 4 drwxr-xr-x 2 root root 4096 Nov 15 15:50 snippets/ 4 -rw-r--r-- 1 root root 664 Feb 4 2019 uwsgi_params 4 -rw-r--r-- 1 root root 3071 Feb 4 2019 win-utf 编辑Nginx服务器配置 更改/etc/nginx/sites-enabled下服务器配置文件：\nserver { listen 443 ssl; #填写绑定证书的域名 server_name comfluter.life; #证书文件名称 ssl_certificate 1_comfluter.life_bundle.crt; #私钥文件名称 ssl_certificate_key 2_comfluter.life.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { #网站主页路径。此路径仅供参考，具体请您按照实际目录操作。 #例如，您的网站运行目录在/etc/www下，则填写/etc/www。 root /home/ubuntu/www/Blogs/Personal; index index.html index.htm; } } server { listen 80; #填写绑定证书的域名 server_name comfluter.life; #把http的域名请求转成https return 301 https://$host$request_uri; } 配置中前半部分为https网页服务，后半部分为将http请求重定向至https请求\n验证配置文件：\nroot@VM-24-3-ubuntu:/etc/nginx# nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful 重启Nginx服务器：nginx -s reload\nhttps访问！ 此时输入comfluter.life访问时即可看到已经是https连接\n \nDebugging 更改成为https连接后博客的搜索功能出现问题，浏览器提示提交的表单不安全并阻止了搜索表单的提交。问题在于没有更改hugo博客配置文件中的baseURL字段，将其改为baseurl: https://comfluter.life即可解决。\n","date":"2021-11-21T00:00:00Z","permalink":"https://comfluter.life/p/%E5%9C%A8nginx%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2ssl%E8%AF%81%E4%B9%A6/","title":"在Nginx服务器上部署SSL证书"},{"content":"21.11.22 锁链  香农-奈奎斯特采样定律 测量：测不准原理  高速成像：  STEAM：10e-10 second 时间分辨率 STAMP：10e-12 second 最先进：10e-15 second 接近电子转移过程的时长！      information in imaging  香农：硕士论文：信息学开山  做一些无聊的事？还是有自己独特的思考？    yes and no question How many questions (y/n) must you ask to ensure the color of the ball you have?\n 8 red balls? 4 red \u0026amp; 2 blue \u0026amp; 1 black \u0026amp; 1 white? 2 red \u0026amp; 2 blue \u0026amp; 2 black \u0026amp; 2 white?  香农信息熵 傅里叶变换的信息损失？\n 取傅里叶变换的过程中，可以有位深 二维傅里叶变换，可以通过幅度反演相位 取傅里叶变换再取反变换？相似度有多高？  SSMS   傅里叶变换过后低频信息密集，高频信息稀疏。  JPEG压缩：压缩低频信息，让步给高频信息\nSignal Sparsity 图像中不是每一个频率都要进行采样！可以抽出傅里叶变换中影响比较大的信息量。\n Compressive sensing  通过采样稀疏的键值信号，尽可能好地还原信号    ","date":"2021-11-21T00:00:00Z","permalink":"https://comfluter.life/p/%E9%87%8D%E5%90%AC%E6%88%90%E5%83%8F%E4%B8%96%E7%95%8C%E7%9A%84%E5%A5%87%E5%A2%83/","title":"重听《成像世界的奇境》"},{"content":"序言 在经历许许多多的学习、配置、折腾之后，终于在今天配置好了自己的个人博客。\n在朋友圈、微博盛行的当下，个人博客的风头已过，好像已经是上一个时代的产物了。那么究竟又是什么让我在建站的过程中即使遇到了层层困难，也坚定不移地搭起来这个博客呢？\n第一方面，感觉自己还是需要一个记录与对外表达的窗口。朋友圈等等社交网络固然可以，但是于我来讲似乎显得喧闹了些。我期待的表达，不是浮于表面的事件记录与短暂的情感宣泄。静下心来记录自己成长变化、各阶段真实想法与所思所得才是我我之所需。而这些想法，有时又期待能随时随地回顾，或是与志同道合之人分享。因此介于朋友圈、微博等社交平台与传统纸笔日记之间的个人博客似乎是个不错的选择。从半年前看到王凯师兄的博客便觉心动，到现在终于有了属于自己的一方空间。\n此外，也是最近在学习计算机网络的相关课程。从之前分不清HTTP、URL、TCP等等名词之间的关系的状态一步步地了解了网络的各个方面，而因为课程设计原因深感实践不足。云服务器的配置、连接、博客的搭建与部署、域名的申请与域名解析配置等等正好为动手实践课程内容提供了一个极佳的机会。在搭建服务器、部署博客的过程中也确实不断地将课本中抽象的知识落到实处。\n最后，可能也是最近受龄的影响，觉得自己不能再一天天想着GPA就惶惶不可终日。成天担心对成绩的影响而束手束脚，投入了过多不必要的时间在课业的细枝末节上，生怕漏掉一小点就会有多么大的影响。现在我觉得比较好的态度是：应该投入的时间，我保证投入。除此之外，偶然性是必然有的，考试中等等可能出现的意外情况、偏门的微末之处，实在无必要，也无意义为了它们投入大量的时间。投入了，也不能保证最后的结果。与其如此，正如闫锋老师说的，不如让自己真正做点实在的事出来，在实践中学习，在实践中收获，在主动地做事情的过程当中发挥自己心灵的能动性，让自己过得由己、恣肆、多彩一些。\n因此，也希望这个博客在记录我个人所思所想以外，能够带动我走出一天天为了成绩而焦虑的状态之中，真正地敢于放手去做自己喜欢的事，也才真正能做成自己喜欢的事。\n建站小记  21.11.05 购买腾讯云服务器、购买域名comfluter.life，熟悉linux服务器操作与hugo工具基本使用 21.11.13 在询问完王凯师兄hugo博客部署方法以后，学习hugo模板使用与博客搭建、github使用、github actions + 云服务器自动部署。但是卡在了最后一步Nginx服务器配置，使得服务器端页面一直显示404。 21.11.15 由于Nginx服务器的问题，以及之前摸索阶段各种误操作，决定直接重置腾讯云服务器，将服务器端的功能重新搭建。完成服务器基本设置后激活root账户并配置ssh登录信息，重写了github pages，安装Nginx，以root账户运行，配置Nginx。 21.11.19 由于使用主题时采用了git submodule的方式，而github同步时不同步submodule导致各种错误，重新使用git clone方式引入了主题，重新搭建了博客与github repo，并配置github actions。 21.11.19 解决github actions css无法加载问题，使用git submodule直接推送到github pages，但发现问题仍然存在。最终确定问题在baseURL上，改好后部署。 21.11.19 写下这篇hello world文档。  动手去做一个项目确实是学习的高效方法。通过搭建博客，至少熟悉了以下内容：\n 云服务器 Linux命令行 git命令行操作 git submodule github全流程 github pages github actions hugo使用 域名配置与域名解析 防火墙配置 Nginx服务器搭建  其中许多是以前多次觉得应该去做，而没多久又半途而废的。放弃的理由大概是陷入极多的知识内容而毫无方向，也就失去了学习的意义，但为了一个目标去做，许多事情就顺理成章了。\n希望以后能以更多项目为依托，让自己不断学习、进步。\nlink built with hugo and using theme \u0026ldquo;Stack\u0026rdquo;\nStack Chinese documentation\nicons\n","date":"2021-11-19T00:00:00Z","image":"https://comfluter.life/p/hello-world/cover_hu8fe24aed48b4970acc8d4892530f8a6f_213999_120x120_fill_q75_box_smart1.jpg","permalink":"https://comfluter.life/p/hello-world/","title":"Hello, World!"}]